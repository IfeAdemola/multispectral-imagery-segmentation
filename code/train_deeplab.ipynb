{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from datasets import Forest, ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11, 64, 64])\n",
      "torch.Size([10, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = Forest(root_dir=\"/home/k45848/multispectral-imagery-segmentation/data/clean_data/train\", label=True, transform=transform)\n",
    "eval_dataset = Forest(root_dir=\"/home/k45848/multispectral-imagery-segmentation/data/clean_data/eval\", label=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "for X, Y in train_loader:\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "weights = DeepLabV3_ResNet50_Weights\n",
    "weights_backbone = ResNet50_Weights.DEFAULT\n",
    "model = deeplabv3_resnet50(weights=None, weights_backbone=weights_backbone, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model for 10 channels input and 3 classes output\n",
    "#### input channels = 10, output classes = 3\n",
    "input_channels = 11\n",
    "model.backbone.conv1 = torch.nn.Conv2d(input_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.SGD(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(preds, labels):\n",
    "    iou = 0\n",
    "    for cls in range(num_classes):\n",
    "        intersection = ((preds== cls) & (labels==cls)).sum()\n",
    "        union = ((preds== cls) | (labels==cls)).sum()\n",
    "        if union > 0:\n",
    "            iou += float(intersection) / float(union)\n",
    "    return iou / num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    intersection = 0\n",
    "    union = 0\n",
    "    total_iou = 0\n",
    "    pbar = tqdm(total=len(train_loader), desc=\"[Train]\")\n",
    "\n",
    "    for images, labels  in train_loader:\n",
    "\n",
    "        # reset gradients\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # move data to gpu if model is on gpu\n",
    "        images =images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(images)[\"out\"]\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        # compute accuracy\n",
    "        predicted_labels = torch.argmax(preds, dim=1)\n",
    "        intersection += torch.logical_and(predicted_labels, labels).sum().item()\n",
    "        union += torch.logical_or(predicted_labels, labels).sum().item()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        \n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = train_loss / len(train_dataset)\n",
    "    epoch_iou = intersection/union\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k45848/miniconda3/envs/Thesis/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712609048481/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Epoch 1/10: 100%|██████████| 1181/1181 [01:23<00:00, 14.18batch/s, loss=0.655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1181/1181 [01:19<00:00, 14.78batch/s, loss=0.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1181/1181 [01:13<00:00, 15.98batch/s, loss=0.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1181/1181 [01:16<00:00, 15.34batch/s, loss=0.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.4398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1181/1181 [01:17<00:00, 15.31batch/s, loss=0.405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.4295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1181/1181 [01:14<00:00, 15.93batch/s, loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.4164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1181/1181 [01:13<00:00, 16.14batch/s, loss=0.382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.4049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1181/1181 [01:15<00:00, 15.54batch/s, loss=0.372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.3945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1181/1181 [01:22<00:00, 14.33batch/s, loss=0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1181/1181 [01:18<00:00, 14.99batch/s, loss=0.359]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.3800\n",
      "Training finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop with tqdm\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Wrap the train_loader with tqdm to add a progress bar\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as t:\n",
    "        for images, labels in t:\n",
    "            # Move data to device (e.g., GPU if available)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)['out']\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            t.set_postfix(loss=running_loss / ((t.n + 1) * train_loader.batch_size))\n",
    "            t.update()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Training finished.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
